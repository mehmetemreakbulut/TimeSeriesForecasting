{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718e3e6b-68df-4480-8acb-a7475481142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "categories = np.load('./categories.npy')\n",
    "valid_periods = np.load('./valid_periods.npy')\n",
    "training_data = np.load('./training_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e98ea7b-e608-4d48-ae0b-5002c70cbe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48000 entries, 0 to 47999\n",
      "Columns: 2776 entries, 0 to 2775\n",
      "dtypes: float64(2776)\n",
      "memory usage: 1016.6 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "training_data_df = pd.DataFrame(training_data)\n",
    "training_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b7ae85-8e83-4496-99b3-8bc2fa0ccc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/hive_retrieval_engine/test_venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "reshaped_categories = categories.reshape(-1, 1)\n",
    "onehot_categories = encoder.fit_transform(reshaped_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06a63c09-e3db-42c8-80a8-cc65de21cac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46560, 2776), (46560, 2), (46560, 6), (1440, 2776), (1440, 2), (1440, 6))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the indices of the time series into training and validation sets\n",
    "train_indices, val_indices = train_test_split(np.arange(len(training_data_df)), test_size=0.2, random_state=42, stratify=categories)\n",
    "\n",
    "# Use these indices to create training and validation sets\n",
    "train_set = training_data_df.iloc[train_indices]\n",
    "valid_periods_train = valid_periods[train_indices]\n",
    "onehot_categories_train = onehot_categories[train_indices]\n",
    "\n",
    "val_set = training_data_df.iloc[val_indices]\n",
    "valid_periods_val = valid_periods[val_indices]\n",
    "onehot_categories_val = onehot_categories[val_indices]\n",
    "\n",
    "train_set.shape, valid_periods_train.shape, onehot_categories_train.shape, val_set.shape, valid_periods_val.shape, onehot_categories_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d79a3f25-5924-4b43-8fa7-3c9f559438dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_padding_length(sq, w, t, s):\n",
    "    cycle = w + t\n",
    "    if sq <= cycle: return cycle - sq\n",
    "    else:\n",
    "        m = (sq - cycle) % s\n",
    "        if m == 0: return m\n",
    "        else: return s - m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7346edf3-51bf-4746-beba-af30ea9385d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, valid_periods, categories, window, telescope, stride=1):\n",
    "\n",
    "    input_sequences = []\n",
    "    input_categories = []\n",
    "    output_sequences = []\n",
    "\n",
    "\n",
    "    for i in range(len(valid_periods)):\n",
    "        start, end = valid_periods[i]\n",
    "        category = categories[i]\n",
    "\n",
    "        sequence = df.iloc[i, start:end].values\n",
    "\n",
    "        padding_length = calculate_padding_length(len(sequence), window, telescope, stride)\n",
    "        sequence = np.pad(sequence, (padding_length, 0), mode='constant', constant_values=0)\n",
    "\n",
    "        for j in range(0, len(sequence) - window - telescope + 1, stride):\n",
    "            input_seq = sequence[j:(j + window)]\n",
    "            output_seq = sequence[(j + window):(j + window + telescope)]\n",
    "\n",
    "            input_sequences.append(input_seq)\n",
    "            input_categories.append(category)\n",
    "            output_sequences.append(output_seq)\n",
    "\n",
    "    return np.array(input_sequences), np.array(input_categories), np.array(output_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f67b490f-a0c9-45f0-a156-b1844f70b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 100\n",
    "telescope = 9\n",
    "stride = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac876d31-15de-4d56-8a40-2cd1fe227cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((549460, 100), (549460, 6), (549460, 9), (17774, 100), (17774, 6), (17774, 9))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_train_category, y_train = create_sequences(train_set, valid_periods_train, onehot_categories_train, window, telescope, stride)\n",
    "X_val, X_val_category, y_val = create_sequences(val_set, valid_periods_val, onehot_categories_val, window, telescope, stride)\n",
    "X_train.shape, X_train_category.shape, y_train.shape, X_val.shape, X_val_category.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96ccfa34-4ec6-40a5-a4b6-cb9385fce987",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (window, 1)\n",
    "category_shape = (6, )\n",
    "output_shape = (telescope, 1)\n",
    "batch_size = 32\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d15ff86c-da42-4b89-86f2-07408b1f9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as tfkl\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_CONV_LSTM_model_with_categories(input_shape, category_shape, output_shape):\n",
    "\n",
    "    # Time series input\n",
    "    time_series_input = tfkl.Input(shape=input_shape, name='time_series_input')\n",
    "    x = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True, name='bidirectional_lstm'))(time_series_input)\n",
    "    x = tfkl.Bidirectional(tfkl.LSTM(32, return_sequences=True, name='bidirectional_lstm_2'))(x)\n",
    "\n",
    "    # Attention mechanism\n",
    "    attention = tfkl.Attention(name='attention')([x, x])\n",
    "\n",
    "    x = tfkl.Conv1D(128, 3, padding='same', activation='relu')(attention)\n",
    "    x = tfkl.Dropout(0.2)(x)\n",
    "\n",
    "    # Category input\n",
    "    category_input = tfkl.Input(shape=category_shape, name='category_input')\n",
    "    category_processed = tfkl.Dense(20, activation='relu')(category_input)\n",
    "\n",
    "    # Combine the processed inputs\n",
    "    combined = tfkl.Concatenate()([x, tfkl.RepeatVector(input_shape[0])(category_processed)])\n",
    "\n",
    "    # Continue with convolutional layers\n",
    "    x = tfkl.Conv1D(128, 3, padding='same', activation='relu')(combined)\n",
    "    x = tfkl.Dropout(0.2)(x)\n",
    "\n",
    "    output_layer = tfkl.Conv1D(output_shape[1], 3, padding='same')(x)\n",
    "    crop_size = output_layer.shape[1] - output_shape[0]\n",
    "    output_layer = tfkl.Cropping1D((0, crop_size))(output_layer)\n",
    "\n",
    "    # Construct the model\n",
    "    model = tf.keras.Model(inputs=[time_series_input, category_input], outputs=output_layer, name='CONV_LSTM_with_Categories')\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4fec35e-c9e1-4324-a377-51a48735928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_CONV_LSTM_model_with_categories(input_shape, category_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c5facab-767c-46c0-b80b-2addb7fae357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CONV_LSTM_with_Categories\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " time_series_input (InputLa  [(None, 100, 1)]             0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirecti  (None, 100, 128)             33792     ['time_series_input[0][0]']   \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirecti  (None, 100, 64)              41216     ['bidirectional_2[0][0]']     \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 100, 64)              0         ['bidirectional_3[0][0]',     \n",
      "                                                                     'bidirectional_3[0][0]']     \n",
      "                                                                                                  \n",
      " category_input (InputLayer  [(None, 6)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 100, 128)             24704     ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 20)                   140       ['category_input[0][0]']      \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 100, 128)             0         ['conv1d_3[0][0]']            \n",
      "                                                                                                  \n",
      " repeat_vector_1 (RepeatVec  (None, 100, 20)              0         ['dense_1[0][0]']             \n",
      " tor)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 100, 148)             0         ['dropout_2[0][0]',           \n",
      " )                                                                   'repeat_vector_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 100, 128)             56960     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 100, 128)             0         ['conv1d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 100, 1)               385       ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " cropping1d_1 (Cropping1D)   (None, 9, 1)                 0         ['conv1d_5[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 157197 (614.05 KB)\n",
      "Trainable params: 157197 (614.05 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "from tensorflow import keras as tfk\n",
    "tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3fe2f7-62fa-40a7-ade1-f6896b7bfb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 14:59:48.832164: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11080\" } environment { key: \"cudnn\" value: \"8600\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14298316800 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-12-19 14:59:51.995629: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-12-19 14:59:58.820519: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555fbcd2e060 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-19 14:59:58.820547: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-12-19 14:59:58.925080: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-19 14:59:59.387615: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14154/14154 [==============================] - ETA: 0s - loss: 0.0137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 15:03:26.386569: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11080\" } environment { key: \"cudnn\" value: \"8600\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14298316800 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14154/14154 [==============================] - 244s 16ms/step - loss: 0.0137 - val_loss: 0.0095 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "14154/14154 [==============================] - 220s 16ms/step - loss: 0.0100 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "14154/14154 [==============================] - 220s 16ms/step - loss: 0.0090 - val_loss: 0.0081 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "13871/14154 [============================>.] - ETA: 3s - loss: 0.0085"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=10,\n",
    "    factor=0.1,\n",
    "    min_lr=1e-5\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x = [X_train, X_train_category],\n",
    "    y = y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = ([X_val, X_val_category], y_val),\n",
    "    callbacks = [\n",
    "        early_stopping,\n",
    "        reduce_lr\n",
    "    ]\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af656f9a-f3a9-4288-b9fc-a60284438e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.01369, 0.00952\n",
      "Epoch 1: 0.00998, 0.00899\n",
      "Epoch 2: 0.00903, 0.00806\n",
      "Epoch 3: 0.00855, 0.00784\n",
      "Epoch 4: 0.00897, 0.00958\n",
      "Epoch 5: 0.00909, 0.00786\n",
      "Epoch 6: 0.00848, 0.00790\n",
      "Epoch 7: 0.00819, 0.00768\n",
      "Epoch 8: 0.00801, 0.00848\n",
      "Epoch 9: 0.00794, 0.00752\n",
      "Epoch 10: 0.00863, 0.00886\n",
      "Epoch 11: 0.00831, 0.00783\n",
      "Epoch 12: 0.00785, 0.00735\n",
      "Epoch 13: 0.00771, 0.00747\n",
      "Epoch 14: 0.00764, 0.00756\n",
      "Epoch 15: 0.00757, 0.00728\n",
      "Epoch 16: 0.00750, 0.00744\n",
      "Epoch 17: 0.00746, 0.00726\n",
      "Epoch 18: 0.00741, 0.00718\n",
      "Epoch 19: 0.00736, 0.00711\n",
      "Epoch 20: 0.00732, 0.00757\n",
      "Epoch 21: 0.00727, 0.00699\n",
      "Epoch 22: 0.00723, 0.00715\n",
      "Epoch 23: 0.00720, 0.00711\n",
      "Epoch 24: 0.00717, 0.00714\n",
      "Epoch 25: 0.00714, 0.00701\n",
      "Epoch 26: 0.00711, 0.00696\n",
      "Epoch 27: 0.00707, 0.00703\n",
      "Epoch 28: 0.00705, 0.00714\n",
      "Epoch 29: 0.00702, 0.00698\n",
      "Epoch 30: 0.00700, 0.00694\n",
      "Epoch 31: 0.00697, 0.00721\n",
      "Epoch 32: 0.00660, 0.00685\n",
      "Epoch 33: 0.00654, 0.00692\n",
      "Epoch 34: 0.00651, 0.00698\n",
      "Epoch 35: 0.00650, 0.00692\n",
      "Epoch 36: 0.00648, 0.00709\n",
      "Epoch 37: 0.00647, 0.00685\n",
      "Epoch 38: 0.00646, 0.00703\n",
      "Epoch 39: 0.00645, 0.00694\n",
      "Epoch 40: 0.00644, 0.00688\n",
      "Epoch 41: 0.00643, 0.00701\n",
      "Epoch 42: 0.00643, 0.00695\n",
      "Epoch 43: 0.00638, 0.00692\n",
      "Epoch 44: 0.00637, 0.00696\n",
      "Epoch 45: 0.00637, 0.00694\n",
      "Epoch 46: 0.00637, 0.00692\n",
      "Epoch 47: 0.00636, 0.00690\n",
      "Epoch 48: 0.00636, 0.00696\n",
      "Epoch 49: 0.00636, 0.00691\n",
      "Epoch 50: 0.00636, 0.00694\n",
      "Epoch 51: 0.00636, 0.00694\n",
      "Epoch 52: 0.00636, 0.00696\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(history['loss']):\n",
    "    print(f\"Epoch {i}: {history['loss'][i]:.5f}, {history['val_loss'][i]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259609c-78ca-4421-9453-2f6061b0a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "best_epoch = np.argmin(history['val_loss'])\n",
    "plt.figure(figsize=(17,4))\n",
    "plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
    "plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
    "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "plt.title('Mean Squared Error (Loss)')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18,3))\n",
    "plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n",
    "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "938c4233-34bf-4a87-b396-4f8cbe197ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_tp9_ws100_att/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_tp9_ws100_att/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('conv_lstm_tp9_ws100_att')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97a5b0-c9e3-415f-98cd-27d5101daeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip model.zip -r conv_lstm_tp9_ws100_att/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe2498-0460-456a-bfcf-98db8144631f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
