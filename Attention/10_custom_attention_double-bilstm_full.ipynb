{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb93a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training data is increased to address if data scarcity is present in the more complex custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718e3e6b-68df-4480-8acb-a7475481142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "categories = np.load('./categories.npy')\n",
    "valid_periods = np.load('./valid_periods.npy')\n",
    "training_data = np.load('./training_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e98ea7b-e608-4d48-ae0b-5002c70cbe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48000 entries, 0 to 47999\n",
      "Columns: 2776 entries, 0 to 2775\n",
      "dtypes: float64(2776)\n",
      "memory usage: 1016.6 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "training_data_df = pd.DataFrame(training_data)\n",
    "training_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b7ae85-8e83-4496-99b3-8bc2fa0ccc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/hive_retrieval_engine/test_venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "reshaped_categories = categories.reshape(-1, 1)\n",
    "onehot_categories = encoder.fit_transform(reshaped_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a63c09-e3db-42c8-80a8-cc65de21cac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46560, 2776), (46560, 2), (46560, 6), (1440, 2776), (1440, 2), (1440, 6))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the indices of the time series into training and validation sets\n",
    "train_indices, val_indices = train_test_split(np.arange(len(training_data_df)), test_size=0.03, random_state=42, stratify=categories)\n",
    "\n",
    "# Use these indices to create training and validation sets\n",
    "train_set = training_data_df.iloc[train_indices]\n",
    "valid_periods_train = valid_periods[train_indices]\n",
    "onehot_categories_train = onehot_categories[train_indices]\n",
    "\n",
    "val_set = training_data_df.iloc[val_indices]\n",
    "valid_periods_val = valid_periods[val_indices]\n",
    "onehot_categories_val = onehot_categories[val_indices]\n",
    "\n",
    "train_set.shape, valid_periods_train.shape, onehot_categories_train.shape, val_set.shape, valid_periods_val.shape, onehot_categories_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d79a3f25-5924-4b43-8fa7-3c9f559438dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_padding_length(sq, w, t, s):\n",
    "    cycle = w + t\n",
    "    if sq <= cycle: return cycle - sq\n",
    "    else:\n",
    "        m = (sq - cycle) % s\n",
    "        if m == 0: return m\n",
    "        else: return s - m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7346edf3-51bf-4746-beba-af30ea9385d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, valid_periods, categories, window, telescope, stride=1):\n",
    "\n",
    "    input_sequences = []\n",
    "    input_categories = []\n",
    "    output_sequences = []\n",
    "\n",
    "\n",
    "    for i in range(len(valid_periods)):\n",
    "        start, end = valid_periods[i]\n",
    "        category = categories[i]\n",
    "\n",
    "        sequence = df.iloc[i, start:end].values\n",
    "\n",
    "        padding_length = calculate_padding_length(len(sequence), window, telescope, stride)\n",
    "        sequence = np.pad(sequence, (padding_length, 0), mode='constant', constant_values=0)\n",
    "\n",
    "        for j in range(0, len(sequence) - window - telescope + 1, stride):\n",
    "            input_seq = sequence[j:(j + window)]\n",
    "            output_seq = sequence[(j + window):(j + window + telescope)]\n",
    "\n",
    "            input_sequences.append(input_seq)\n",
    "            input_categories.append(category)\n",
    "            output_sequences.append(output_seq)\n",
    "\n",
    "    return np.array(input_sequences), np.array(input_categories), np.array(output_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f67b490f-a0c9-45f0-a156-b1844f70b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 100\n",
    "telescope = 9\n",
    "stride = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac876d31-15de-4d56-8a40-2cd1fe227cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((549460, 100), (549460, 6), (549460, 9), (17774, 100), (17774, 6), (17774, 9))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_train_category, y_train = create_sequences(train_set, valid_periods_train, onehot_categories_train, window, telescope, stride)\n",
    "X_val, X_val_category, y_val = create_sequences(val_set, valid_periods_val, onehot_categories_val, window, telescope, stride)\n",
    "X_train.shape, X_train_category.shape, y_train.shape, X_val.shape, X_val_category.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ccfa34-4ec6-40a5-a4b6-cb9385fce987",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (window, 1)\n",
    "category_shape = (6, )\n",
    "output_shape = (telescope, 1)\n",
    "batch_size = 32\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d15ff86c-da42-4b89-86f2-07408b1f9da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 19:11:48.127463: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-19 19:11:48.170004: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-19 19:11:48.926894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.layers as tfkl\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_CONV_LSTM_model_with_categories(input_shape, category_shape, output_shape):\n",
    "\n",
    "    # Time series input\n",
    "    time_series_input = tfkl.Input(shape=input_shape, name='time_series_input')\n",
    "    x = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True, name='bidirectional_lstm'))(time_series_input)\n",
    "    x = tfkl.Bidirectional(tfkl.LSTM(32, return_sequences=True, name='bidirectional_lstm_2'))(x)\n",
    "\n",
    "    # Attention mechanism\n",
    "    attention = tfkl.Attention(name='attention')([x, x])\n",
    "\n",
    "    x = tfkl.Conv1D(128, 3, padding='same', activation='relu')(attention)\n",
    "    x = tfkl.Dropout(0.2)(x)\n",
    "\n",
    "    # Category input\n",
    "    category_input = tfkl.Input(shape=category_shape, name='category_input')\n",
    "    category_processed = tfkl.Dense(20, activation='relu')(category_input)\n",
    "\n",
    "    # Combine the processed inputs\n",
    "    combined = tfkl.Concatenate()([x, tfkl.RepeatVector(input_shape[0])(category_processed)])\n",
    "\n",
    "    # Continue with convolutional layers\n",
    "    x = tfkl.Conv1D(128, 3, padding='same', activation='relu')(combined)\n",
    "    x = tfkl.Dropout(0.2)(x)\n",
    "\n",
    "    output_layer = tfkl.Conv1D(output_shape[1], 3, padding='same')(x)\n",
    "    crop_size = output_layer.shape[1] - output_shape[0]\n",
    "    output_layer = tfkl.Cropping1D((0, crop_size))(output_layer)\n",
    "\n",
    "    # Construct the model\n",
    "    model = tf.keras.Model(inputs=[time_series_input, category_input], outputs=output_layer, name='CONV_LSTM_with_Categories')\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4fec35e-c9e1-4324-a377-51a48735928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 19:11:49.775704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-19 19:11:49.816345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-19 19:11:49.818022: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-19 19:11:49.820437: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-19 19:11:49.821976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-19 19:11:49.823486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-19 19:11:50.574784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-19 19:11:50.575826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-19 19:11:50.576616: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-19 19:11:50.577345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13635 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = build_CONV_LSTM_model_with_categories(input_shape, category_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c5facab-767c-46c0-b80b-2addb7fae357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CONV_LSTM_with_Categories\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " time_series_input (InputLa  [(None, 100, 1)]             0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 100, 128)             33792     ['time_series_input[0][0]']   \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 100, 64)              41216     ['bidirectional[0][0]']       \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 100, 64)              0         ['bidirectional_1[0][0]',     \n",
      "                                                                     'bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " category_input (InputLayer  [(None, 6)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 100, 128)             24704     ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 20)                   140       ['category_input[0][0]']      \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 100, 128)             0         ['conv1d[0][0]']              \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVecto  (None, 100, 20)              0         ['dense[0][0]']               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 100, 148)             0         ['dropout[0][0]',             \n",
      "                                                                     'repeat_vector[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 100, 128)             56960     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 100, 128)             0         ['conv1d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 100, 1)               385       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " cropping1d (Cropping1D)     (None, 9, 1)                 0         ['conv1d_2[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 157197 (614.05 KB)\n",
      "Trainable params: 157197 (614.05 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "from tensorflow import keras as tfk\n",
    "tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f3fe2f7-62fa-40a7-ade1-f6896b7bfb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 19:11:57.461730: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11080\" } environment { key: \"cudnn\" value: \"8600\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14298316800 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-12-19 19:11:58.758276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-12-19 19:11:59.749464: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7e1c100510 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-19 19:11:59.749489: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-12-19 19:11:59.754261: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-19 19:11:59.872502: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17171/17171 [==============================] - ETA: 0s - loss: 0.0118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 19:16:01.261255: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11080\" } environment { key: \"cudnn\" value: \"8600\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14298316800 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17171/17171 [==============================] - 252s 14ms/step - loss: 0.0118 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0090 - val_loss: 0.0078 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0108 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0084 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0081 - val_loss: 0.0077 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0080 - val_loss: 0.0071 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0078 - val_loss: 0.0071 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0077 - val_loss: 0.0069 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0077 - val_loss: 0.0068 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0076 - val_loss: 0.0070 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "17171/17171 [==============================] - 242s 14ms/step - loss: 0.0075 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0075 - val_loss: 0.0068 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "17171/17171 [==============================] - 242s 14ms/step - loss: 0.0074 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "17171/17171 [==============================] - 243s 14ms/step - loss: 0.0074 - val_loss: 0.0069 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "17171/17171 [==============================] - 242s 14ms/step - loss: 0.0073 - val_loss: 0.0066 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0073 - val_loss: 0.0066 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0072 - val_loss: 0.0066 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0072 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0072 - val_loss: 0.0064 - lr: 0.0010\n",
      "Epoch 20/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0071 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 21/40\n",
      "17171/17171 [==============================] - 248s 14ms/step - loss: 0.0071 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 22/40\n",
      "17171/17171 [==============================] - 263s 15ms/step - loss: 0.0071 - val_loss: 0.0064 - lr: 0.0010\n",
      "Epoch 23/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0071 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 24/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0070 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 25/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0070 - val_loss: 0.0064 - lr: 0.0010\n",
      "Epoch 26/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0070 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 27/40\n",
      "17171/17171 [==============================] - 240s 14ms/step - loss: 0.0069 - val_loss: 0.0064 - lr: 0.0010\n",
      "Epoch 28/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0069 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 29/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0069 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 30/40\n",
      "17171/17171 [==============================] - 240s 14ms/step - loss: 0.0065 - val_loss: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0065 - val_loss: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0064 - val_loss: 0.0062 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0064 - val_loss: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "17171/17171 [==============================] - 242s 14ms/step - loss: 0.0064 - val_loss: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "17171/17171 [==============================] - 240s 14ms/step - loss: 0.0064 - val_loss: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0064 - val_loss: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0064 - val_loss: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 38/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0064 - val_loss: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 39/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0064 - val_loss: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 40/40\n",
      "17171/17171 [==============================] - 241s 14ms/step - loss: 0.0064 - val_loss: 0.0063 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=10,\n",
    "    factor=0.1,\n",
    "    min_lr=1e-5\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x = [X_train, X_train_category],\n",
    "    y = y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = ([X_val, X_val_category], y_val),\n",
    "    callbacks = [\n",
    "        early_stopping,\n",
    "        reduce_lr\n",
    "    ]\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259609c-78ca-4421-9453-2f6061b0a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "best_epoch = np.argmin(history['val_loss'])\n",
    "plt.figure(figsize=(17,4))\n",
    "plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
    "plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
    "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "plt.title('Mean Squared Error (Loss)')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18,3))\n",
    "plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n",
    "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "938c4233-34bf-4a87-b396-4f8cbe197ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_tp9_ws100_att_all/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_tp9_ws100_att_all/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('conv_lstm_tp9_ws100_att_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d97a5b0-c9e3-415f-98cd-27d5101daeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: conv_lstm_tp9_ws100_att_all/ (stored 0%)\n",
      "  adding: conv_lstm_tp9_ws100_att_all/keras_metadata.pb (deflated 93%)\n",
      "  adding: conv_lstm_tp9_ws100_att_all/saved_model.pb (deflated 90%)\n",
      "  adding: conv_lstm_tp9_ws100_att_all/variables/ (stored 0%)\n",
      "  adding: conv_lstm_tp9_ws100_att_all/variables/variables.index (deflated 67%)\n",
      "  adding: conv_lstm_tp9_ws100_att_all/variables/variables.data-00000-of-00001 (deflated 21%)\n",
      "  adding: conv_lstm_tp9_ws100_att_all/fingerprint.pb (stored 0%)\n",
      "  adding: conv_lstm_tp9_ws100_att_all/assets/ (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "!zip model2.zip -r conv_lstm_tp9_ws100_att_all/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe2498-0460-456a-bfcf-98db8144631f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
