{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df85d6b9-9149-4a90-a050-7790ecf59a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "categories = np.load('./categories.npy')\n",
    "valid_periods = np.load('./valid_periods.npy')\n",
    "training_data = np.load('./training_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34786673-c201-4dc6-92a4-d490c94d948a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48000 entries, 0 to 47999\n",
      "Columns: 2776 entries, 0 to 2775\n",
      "dtypes: float64(2776)\n",
      "memory usage: 1016.6 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "training_data_df = pd.DataFrame(training_data)\n",
    "training_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca031c0a-a5c5-4731-9dd8-a6188d4459e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/hive_retrieval_engine/test_venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "reshaped_categories = categories.reshape(-1, 1)\n",
    "onehot_categories = encoder.fit_transform(reshaped_categories)\n",
    "\n",
    "onehot_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85375b81-05f3-424f-bd67-f83618e87326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46560, 2776), (46560, 2), (46560, 6), (1440, 2776), (1440, 2), (1440, 6))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the indices of the time series into training and validation sets\n",
    "train_indices, val_indices = train_test_split(np.arange(len(training_data_df)), test_size=0.03, random_state=42, stratify=categories)\n",
    "\n",
    "# Use these indices to create training and validation sets\n",
    "train_set = training_data_df.iloc[train_indices]\n",
    "valid_periods_train = valid_periods[train_indices]\n",
    "onehot_categories_train = onehot_categories[train_indices]\n",
    "\n",
    "val_set = training_data_df.iloc[val_indices]\n",
    "valid_periods_val = valid_periods[val_indices]\n",
    "onehot_categories_val = onehot_categories[val_indices]\n",
    "\n",
    "train_set.shape, valid_periods_train.shape, onehot_categories_train.shape, val_set.shape, valid_periods_val.shape, onehot_categories_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57bae90a-d8d7-461c-9f0d-72de0217a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_padding_length(sq, w, t, s):\n",
    "    cycle = w + t\n",
    "    if sq <= cycle: return cycle - sq\n",
    "    else:\n",
    "        m = (sq - cycle) % s\n",
    "        if m == 0: return m\n",
    "        else: return s - m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b64dd64-1124-4b8a-9345-5e2532662150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, valid_periods, categories, window, telescope, stride):\n",
    "\n",
    "    input_sequences = []\n",
    "    input_categories = []\n",
    "    output_sequences = []\n",
    "    \n",
    "\n",
    "    for i in range(len(valid_periods)):\n",
    "        start, end = valid_periods[i]\n",
    "        category = categories[i]\n",
    "        \n",
    "        sequence = df.iloc[i, start:end].values\n",
    "        \n",
    "        padding_length = calculate_padding_length(len(sequence), window, telescope, stride)\n",
    "        sequence = np.pad(sequence, (padding_length, 0), mode='constant', constant_values=0)\n",
    "\n",
    "        for j in range(0, len(sequence) - window - telescope + 1, stride):\n",
    "            input_seq = sequence[j:(j + window)]\n",
    "            output_seq = sequence[(j + window):(j + window + telescope)]\n",
    "            \n",
    "            input_sequences.append(input_seq)\n",
    "            input_categories.append(category)\n",
    "            output_sequences.append(output_seq)\n",
    "\n",
    "    return np.array(input_sequences), np.array(input_categories), np.array(output_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e94ceadf-2d7b-4c75-b8c0-80a160fe31aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 100\n",
    "telescope = 18\n",
    "stride = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ff8d9d1-f06b-4983-9148-7cdadd1639ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((835049, 100),\n",
       " (835049, 6),\n",
       " (835049, 18),\n",
       " (27142, 100),\n",
       " (27142, 6),\n",
       " (27142, 18))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_train_category, y_train = create_sequences(train_set, valid_periods_train, onehot_categories_train, window, telescope, stride)\n",
    "X_val, X_val_category, y_val = create_sequences(val_set, valid_periods_val, onehot_categories_val, window, telescope, stride)\n",
    "X_train.shape, X_train_category.shape, y_train.shape, X_val.shape, X_val_category.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5246f111-13f8-4e90-9b72-e0d66e011836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 12:15:17.134680: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-21 12:15:17.178062: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-21 12:15:17.946400: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "346a495d-8c9c-48db-b322-ee7118894616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pylessons.com/transformers-introduction\n",
    "def positional_encoding(length: int, depth: int):\n",
    "    \"\"\"\n",
    "    Generates a positional encoding for a given length and depth.\n",
    "\n",
    "    Args:\n",
    "        length (int): The length of the input sequence.\n",
    "        depth (int): The depth that represents the dimensionality of the encoding.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: The positional encoding of shape (length, depth).\n",
    "    \"\"\"\n",
    "    depth = depth / 2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "    angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1) \n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "928684b9-a5c5-438b-817e-8ef38891c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A positional encoding layer with a positional encoding that helps the Transformer\n",
    "    to understand the relative position of the inputs. \n",
    "\n",
    "    Methods:\n",
    "        call: Performs the forward pass of the layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_length: int, d_model: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_length (int): The size of the maximum input sequence.\n",
    "            d_model (int): The dimensionality of the pos encoding.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.max_length = max_length\n",
    "        self.d_model = d_model\n",
    "        self.pos_encoding = positional_encoding(length=max_length, depth=d_model)\n",
    "        \n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\" Performs the forward pass of the layer.\n",
    "        \n",
    "        Args:\n",
    "            x (tf.Tensor): The input tensor of shape (batch_size, seq_length).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The output sequence with added positional information. The shape is\n",
    "                (batch_size, seq_length, d_model).\n",
    "        \"\"\"\n",
    "        length = tf.shape(x)[1]\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cd7ee83-d239-4755-8da7-75f85ab0175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, MultiHeadAttention, LayerNormalization, Dropout, Add\n",
    "\n",
    "class TimeSeriesSelfAttention(Layer):\n",
    "    \"\"\"\n",
    "    Implements a self-attention mechanism specifically for time series data. The attention mechanism allows each point in \n",
    "    the sequence to attend to all other points in the same sequence, capturing the global dependencies within the time series.\n",
    "\n",
    "    Attributes:\n",
    "        mha (MultiHeadAttention): The MultiHeadAttention layer.\n",
    "        layernorm (LayerNormalization): The LayerNormalization layer.\n",
    "        dropout (Dropout): The Dropout layer to prevent overfitting.\n",
    "        add (Add): The Add layer to combine inputs and attention outputs.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dropout_rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.layernorm = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.add = Add()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # Self-attention\n",
    "        attn_output = self.mha(inputs, inputs, inputs)\n",
    "        attn_output = self.dropout(attn_output, training=training)\n",
    "        # Add & Norm\n",
    "        out = self.layernorm(self.add([inputs, attn_output]))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08829b6b-7912-4b1b-aaee-99475dbb11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(Layer):\n",
    "    \"\"\"\n",
    "    A class that implements the feed-forward layer.\n",
    "\n",
    "    Methods:\n",
    "        call: Performs the forward pass of the layer.\n",
    "\n",
    "    Attributes:\n",
    "        seq (tf.keras.Sequential): The sequential layer that contains the feed-forward layers. It applies the two feed-forward layers and the dropout layer.\n",
    "        add (tf.keras.layers.Add): The Add layer.\n",
    "        layer_norm (tf.keras.layers.LayerNormalization): The LayerNormalization layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, dff: int, dropout_rate: float=0.1):\n",
    "        \"\"\"\n",
    "        Constructor of the FeedForward layer.\n",
    "\n",
    "        Args:\n",
    "            d_model (int): The dimensionality of the model.\n",
    "            dff (int): The dimensionality of the feed-forward layer.\n",
    "            dropout_rate (float): The dropout rate.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),\n",
    "            tf.keras.layers.Dense(d_model),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        The call function that performs the feed-forward operation. \n",
    "\n",
    "        Args:\n",
    "            x (tf.Tensor): The input sequence of shape (batch_size, seq_length, d_model).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The output sequence of shape (batch_size, seq_length, d_model).\n",
    "        \"\"\"\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cda17b58-7794-4c2b-98ee-ea81a99e4720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A single layer of the Encoder. Usually there are multiple layers stacked on top of each other.\n",
    "\n",
    "    Methods:\n",
    "        call: Performs the forward pass of the layer.\n",
    "\n",
    "    Attributes:\n",
    "        self_attention (GlobalSelfAttention): The global self-attention layer.\n",
    "        ffn (FeedForward): The feed-forward layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, num_heads: int, dff: int, dropout_rate: float=0.1):\n",
    "        \"\"\"\n",
    "        Constructor of the EncoderLayer.\n",
    "\n",
    "        Args:\n",
    "            d_model (int): The dimensionality of the model.\n",
    "            num_heads (int): The number of heads in the multi-head attention layer.\n",
    "            dff (int): The dimensionality of the feed-forward layer.\n",
    "            dropout_rate (float): The dropout rate.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attention = TimeSeriesSelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            d_model=d_model,\n",
    "            dropout_rate=dropout_rate\n",
    "            )\n",
    "\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        The call function that performs the forward pass of the layer.\n",
    "\n",
    "        Args:\n",
    "            x (tf.Tensor): The input sequence of shape (batch_size, seq_length, d_model).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The output sequence of shape (batch_size, seq_length, d_model).\n",
    "        \"\"\"\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00c9579e-3410-4720-a01d-072e02721179",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "    \"\"\"\n",
    "    A custom TensorFlow layer that implements the Encoder.\n",
    "\n",
    "    Methods:\n",
    "        call: Performs the forward pass of the layer.\n",
    "\n",
    "    Attributes:\n",
    "        d_model (int): The dimensionality of the model.\n",
    "        num_layers (int): The number of layers in the encoder.\n",
    "        pos_encoding (Positionalncoding): The positional encoding layer.\n",
    "        enc_layers (list): The list of encoder layers.\n",
    "        dropout (tf.keras.layers.Dropout): The dropout layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers: int, d_model: int, num_heads: int, dff: int, max_length: int, dropout_rate: float=0.1):\n",
    "        \"\"\"\n",
    "        Constructor of the Encoder.\n",
    "\n",
    "        Args:\n",
    "            num_layers (int): The number of layers in the encoder.\n",
    "            d_model (int): The dimensionality of the model.\n",
    "            num_heads (int): The number of heads in the multi-head attention layer.\n",
    "            dff (int): The dimensionality of the feed-forward layer.\n",
    "            max_length (int): The size of the max input sequence.\n",
    "            dropout_rate (float): The dropout rate.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_encoding = PositionalEncoding(max_length=max_length, d_model=d_model)\n",
    "\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model=d_model,\n",
    "                        num_heads=num_heads,\n",
    "                        dff=dff,\n",
    "                        dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        The call function that performs the forward pass of the layer.\n",
    "        \n",
    "        Args:\n",
    "            x (tf.Tensor): The input sequence of shape (batch_size, seq_length).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The output sequence of shape (batch_size, seq_length, d_model).\n",
    "        \"\"\"\n",
    "        x = self.pos_encoding(x)  \n",
    "        # here x has shape `(batch_size, seq_len, d_model)`\n",
    "\n",
    "        # Add dropout.\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "\n",
    "        return x  # Shape `(batch_size, seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72f4ed77-0147-4dea-97d2-12583550858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Flatten, Reshape, RepeatVector\n",
    "\n",
    "def TimeSeriesTransformer(\n",
    "    num_layers: int = 8, \n",
    "    d_model: int = 16, \n",
    "    num_heads: int = 2,\n",
    "    dff: int = 16,\n",
    "    window: int = window,\n",
    "    telescope: int = telescope,\n",
    "    num_categories: int = 6,\n",
    "    dropout_rate: float = 0.2\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    A custom TensorFlow model for time series forecasting using Transformer architecture with categorical inputs.\n",
    "    \"\"\"\n",
    "   # Inputs\n",
    "    time_series_input = Input(shape=(window, 1), dtype=tf.float32)  # Shape: (batch_size, window, 1)\n",
    "    categorical_input = Input(shape=(num_categories,), dtype=tf.float32)  # Shape: (batch_size, num_categories)\n",
    "\n",
    "    # Process Time Series Input\n",
    "    ts_processed = Dense(d_model, activation='relu')(time_series_input)  # Shape: (batch_size, window, d_model)\n",
    "\n",
    "    # Process Categorical Input\n",
    "    cat_processed = Dense(d_model, activation='relu')(categorical_input)  # Shape: (batch_size, d_model)\n",
    "    cat_processed = RepeatVector(window)(cat_processed)  # Shape: (batch_size, window, d_model)\n",
    "\n",
    "    # Combine Time Series and Categorical Data\n",
    "    combined_input = Concatenate(axis=-1)([ts_processed, cat_processed])  # Shape: (batch_size, window, 2*d_model)\n",
    "\n",
    "    # Encoder\n",
    "    encoder_output = Encoder(num_layers, 2*d_model, num_heads, dff, window, dropout_rate)(combined_input)  # Adjusted d_model to 2*d_model\n",
    "\n",
    "    # Output Layer\n",
    "    output = Dense(telescope)(encoder_output[:, -1, :])  # Predicting 'telescope' future values\n",
    "\n",
    "    return tf.keras.Model(inputs=[time_series_input, categorical_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df64b980-f516-499b-beae-70c5471674d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 12:15:18.835590: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 12:15:18.874911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 12:15:18.876571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 12:15:18.878545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 12:15:18.880014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 12:15:18.881445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 12:15:19.629477: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 12:15:19.630471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 12:15:19.631215: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 12:15:19.631956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13635 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = TimeSeriesTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8c62778-ffc0-4810-8017-284013e8fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36cef671-4700-4a8c-94c0-9e5d55568d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 6)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)        [(None, 100, 1)]             0         []                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 16)                   112       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 100, 16)              32        ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVecto  (None, 100, 16)              0         ['dense_1[0][0]']             \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 100, 32)              0         ['dense[0][0]',               \n",
      "                                                                     'repeat_vector[0][0]']       \n",
      "                                                                                                  \n",
      " encoder (Encoder)           (None, 100, 32)              76928     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 32)                   0         ['encoder[0][0]']             \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 18)                   594       ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 77666 (303.38 KB)\n",
      "Trainable params: 77666 (303.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "from tensorflow import keras as tfk\n",
    "tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef7107c4-d5b3-4f98-84bf-85d29bff129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b98ebe7-3fbb-4d01-b8ec-f256e85b8d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13048/13048 [==============================] - 431s 33ms/step - loss: 0.0111 - val_loss: 0.0139 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "13048/13048 [==============================] - 432s 33ms/step - loss: 0.0110 - val_loss: 0.0131 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "13048/13048 [==============================] - 429s 33ms/step - loss: 0.0109 - val_loss: 0.0140 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "13048/13048 [==============================] - 429s 33ms/step - loss: 0.0109 - val_loss: 0.0132 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "13048/13048 [==============================] - 428s 33ms/step - loss: 0.0109 - val_loss: 0.0140 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "13048/13048 [==============================] - 429s 33ms/step - loss: 0.0108 - val_loss: 0.0136 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "13048/13048 [==============================] - 429s 33ms/step - loss: 0.0108 - val_loss: 0.0137 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "13048/13048 [==============================] - 430s 33ms/step - loss: 0.0108 - val_loss: 0.0136 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "13048/13048 [==============================] - 430s 33ms/step - loss: 0.0108 - val_loss: 0.0136 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "13048/13048 [==============================] - 435s 33ms/step - loss: 0.0107 - val_loss: 0.0140 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "13048/13048 [==============================] - 429s 33ms/step - loss: 0.0107 - val_loss: 0.0137 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "13048/13048 [==============================] - 429s 33ms/step - loss: 0.0107 - val_loss: 0.0137 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "13048/13048 [==============================] - 429s 33ms/step - loss: 0.0107 - val_loss: 0.0139 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "13048/13048 [==============================] - 430s 33ms/step - loss: 0.0107 - val_loss: 0.0140 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "13048/13048 [==============================] - 430s 33ms/step - loss: 0.0106 - val_loss: 0.0144 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "13048/13048 [==============================] - 431s 33ms/step - loss: 0.0106 - val_loss: 0.0148 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "13048/13048 [==============================] - 430s 33ms/step - loss: 0.0106 - val_loss: 0.0144 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "13048/13048 [==============================] - 435s 33ms/step - loss: 0.0105 - val_loss: 0.0144 - lr: 1.0000e-05\n",
      "Epoch 19/50\n",
      "13048/13048 [==============================] - 432s 33ms/step - loss: 0.0105 - val_loss: 0.0145 - lr: 1.0000e-05\n",
      "Epoch 20/50\n",
      "13048/13048 [==============================] - 431s 33ms/step - loss: 0.0105 - val_loss: 0.0145 - lr: 1.0000e-05\n",
      "Epoch 21/50\n",
      "13048/13048 [==============================] - 431s 33ms/step - loss: 0.0105 - val_loss: 0.0146 - lr: 1.0000e-05\n",
      "Epoch 22/50\n",
      "13048/13048 [==============================] - 430s 33ms/step - loss: 0.0105 - val_loss: 0.0144 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    mode='min', \n",
    "    patience=20, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    mode='min', \n",
    "    patience=15, \n",
    "    factor=0.1, \n",
    "    min_lr=1e-5\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x = [X_train, X_train_category],\n",
    "    y = y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = ([X_val, X_val_category], y_val),\n",
    "    callbacks = [\n",
    "        early_stopping,\n",
    "        reduce_lr\n",
    "    ]\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "301a9957-f7d5-417e-b7c5-a25c17fea7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: transformer_med/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: transformer_med/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('transformer_med')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "477dcf62-9649-411f-80ca-506a2d88f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: transformer_med/ (stored 0%)\n",
      "  adding: transformer_med/keras_metadata.pb (deflated 95%)\n",
      "  adding: transformer_med/saved_model.pb (deflated 92%)\n",
      "  adding: transformer_med/variables/ (stored 0%)\n",
      "  adding: transformer_med/variables/variables.index (deflated 78%)\n",
      "  adding: transformer_med/variables/variables.data-00000-of-00001 (deflated 18%)\n",
      "  adding: transformer_med/fingerprint.pb (stored 0%)\n",
      "  adding: transformer_med/assets/ (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r transformer_med.zip ./transformer_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bcf070-bec8-4831-9dd4-9bae586656fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
